{
 "metadata": {
  "name": "",
  "signature": "sha256:f71ea4db2bdb6077e1e41726910330f3d232c200fcbee257d7e68248ee473f4e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Lingbuzz Scrapper\n",
      "\n",
      "This python notebook displays some code for scrapping the [Lingbuzz](http://ling.auf.net/lingbuzz) website in order to generate a linguistic-related corpus. The code runs on python 2.7 without a hitch. A few modifications are necessary to ensure compatibility with python 3.4.\n",
      "\n",
      "Lingbuzz is a repository for linguistic papers pertaining to different fields and/or languages. Each paper has a unique ID coded on 6 digits and can be downloaded as a `.pdf`. The website is, unfortunately, surprisingly quirky and unstable and while navigating through it, one may often stumble upon the dreaded _HTTP Error 503: Service Temporarily Unavailable_. The actual scrapping operation may require to be run iteratively in order to ensure the whole corpus is downloaded.\n",
      "\n",
      "Lingbuzz boasts more than 5000 entries but I was able to retrieve only ~2700 of them. The root cause is still under investigation.\n",
      "\n",
      "The generated corpus is saved as a JSON file which can be used to generate a dictionary. The structure of each entry is:\n",
      "\n",
      "* A unique ID as a `string` coded on 6 digits from 0 to 9.\n",
      "    + _cnt_: the number of times the related document was downloaded (`int`).\n",
      "    + _kwd_: a list of keywords related to the document (`[string]`).\n",
      "    + _tit_: the title of the document (`string`)\n",
      "    + _pub_: where the document has been published (`string`); if the document hasn't been published, then it is `N/A`.\n",
      "    + _dat_: the date of publication on Lingbuzz (`string`).\n",
      "    + _aut_: a list containing the names of the authors (`[string]`).\n",
      "    + _ref_: the document ID, same as above (`string`).\n",
      "    + _exc_: a short excerpt, detailing the work presented in the document."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1 - Preliminaries\n",
      "\n",
      "This part is used to import the necessary packages and define some helper functions. The imports have been tuned with `try/except` blocks so as to ensure the compatibility with Python 3.4."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    import urllib.request as urllib2\n",
      "except ImportError:\n",
      "    import urllib2\n",
      "    \n",
      "try:\n",
      "    import http.client as httplib\n",
      "except ImportError:\n",
      "    import httplib\n",
      "    \n",
      "from bs4 import BeautifulSoup\n",
      "import re\n",
      "import json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If a corpus already exists, then it is loaded. Otherwise, an empty dictionary is generated, ready to store the data.\n",
      "\n",
      "_(NOTA: to ensure compatibility with python 3.4, replace 'rb' with 'r')_"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    with open('lingbuzzCorpus.json', 'rb') as infile:\n",
      "        ref_dict = json.load(infile)\n",
      "        print('Corpus successfuly loaded!')\n",
      "        print('Number of entries: {0}'.format(len(ref_dict.keys())))\n",
      "except IOError:\n",
      "    ref_dict = dict()\n",
      "    print('No existing corpus found, empty dictionary generated')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Corpus successfuly loaded!\n",
        "Number of entries: 2721\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Defining the user-agent may be useful as some servers react poorly when confronted to the default python user-agent. We set the user-agent as Mozilla's. The `url_base` variable holds the basic address of the website."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_agent = \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:37.0) Gecko/20100101 Firefox/37.0\"\n",
      "url_base = \"http://lingbuzz.auf.net\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2 - Scrapping\n",
      "\n",
      "The following 3 helper functions perform all the work:\n",
      "\n",
      "* `fetchDocIdAndNextPage` takes an url (`string`) as a parameter and returns a tuple `(id_list, next_page)` where `id_list` is a list of document IDs found on the page and `next_page` is part of the url leading to the next page. The parser used is `html5lib` because, though relatively slower than other parser, it is extremely consistent and prevents the loss of information.\n",
      "* `fetch_doc` takes a document ID (`string`) as a parameter and returns the related webpage, ready to be parsed by BeautifulSoup.\n",
      "* `parse_doc` takes the document returned by `fetch_doc` and the document ID as a `string`; the document is parsed with BeautifulSoup and the useful information is extracted and stored in a dictionary. Said dictionary is returned by the function.\n",
      "\n",
      "_NOTA: to ensure compatibility with python 3.4:_\n",
      "* _replace all instances of `except httplib.IncompleteRead, e:` with `except httplib.IncompleteRead as e:`._\n",
      "* _replace `except ValueError, v:` with `except ValueError as v:`._"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fetchDocIdAndNextPage(url):\n",
      "    \n",
      "    req = urllib2.Request(url)\n",
      "    req.add_header(\"User_Agent\", user_agent)\n",
      "    response = urllib2.urlopen(req)\n",
      "    \n",
      "    try:\n",
      "        page = response.read()\n",
      "    except httplib.IncompleteRead, e:\n",
      "        page = e.partial\n",
      "    response.close()\n",
      "    \n",
      "    id_list = list()\n",
      "    next_page = ''\n",
      "    bs = BeautifulSoup(page, \"html5lib\")\n",
      "    \n",
      "    for item in bs.find_all('a'):\n",
      "        match_id = re.search(r'\\d{6}$', item.get(\"href\"))\n",
      "        match_lk = re.search(r'Next \\d+ articles', item.get_text(strip = True))\n",
      "        if match_id:\n",
      "            id_list.append(match_id.group())\n",
      "        elif match_lk:\n",
      "            next_page = item.get(\"href\")\n",
      "    \n",
      "    return (id_list, next_page)\n",
      "\n",
      "def fetch_doc(doc_id):\n",
      "    \n",
      "    doc_req = urllib2.Request(url_base + \"/lingbuzz/\" + doc_id)\n",
      "    doc_req.add_header(\"User_Agent\", user_agent)\n",
      "    doc_response = urllib2.urlopen(doc_req)\n",
      "    \n",
      "    try:\n",
      "        doc = doc_response.read()\n",
      "    except httplib.IncompleteRead, e:\n",
      "        doc = e.partial\n",
      "    doc_response.close()\n",
      "\n",
      "    return doc\n",
      "\n",
      "def parse_doc(html_doc, doc_id):\n",
      "    \n",
      "    parsed = BeautifulSoup(html_doc, \"html5lib\")\n",
      "    \n",
      "    if parsed:\n",
      "        article = dict()\n",
      "        article[\"ref\"] = doc_id\n",
      "        text_head = parsed.body.center.get_text(\"\\n\", strip = True).lower().split(\"\\n\")\n",
      "        text_body = parsed.body.get_text(\"\\n\", strip = True).lower().split(\"\\n\")\n",
      "        article[\"tit\"] = text_head[0]\n",
      "        article[\"dat\"] = text_head[-1]\n",
      "        article[\"aut\"] = list()\n",
      "        \n",
      "        for val in text_head[1:-1]:\n",
      "            if val != \",\":\n",
      "                article[\"aut\"].append(str(val.encode(\"ascii\", \"ignore\")))\n",
      "        \n",
      "        try:\n",
      "            article[\"pub\"] = text_body[text_body.index(\"published in:\")+1]\n",
      "        except ValueError, v:\n",
      "            article[\"pub\"] = 'N/A'\n",
      "        \n",
      "        article[\"kwd\"] = text_body[text_body.index(\"keywords:\")+1]\n",
      "        article[\"cnt\"] = text_body[text_body.index(\"downloaded:\")+1]\n",
      "        text_bits = list()\n",
      "        \n",
      "        for tb in text_body[text_body.index(article[\"dat\"])+1:text_body.index(\"format:\")]:\n",
      "            text_bits.append(tb)\n",
      "        article[\"exc\"] = ' '.join(text_bits)\n",
      "        \n",
      "        return article\n",
      "    \n",
      "    else:\n",
      "        return None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The cell below may need to be run several times, as the _Error 503_ may pop up from time to time..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "next_url = '/lingbuzz'\n",
      "next_page = url_base + next_url\n",
      "list_url = list()\n",
      "while True:\n",
      "    print('Processing...\\t{0}'.format(next_page))\n",
      "    id_list, next_url = fetchDocIdAndNextPage(next_page)\n",
      "    if next_url == '':\n",
      "        break\n",
      "    else:\n",
      "        next_page = url_base + next_url\n",
      "        list_url.append(next_url)\n",
      "    for id in id_list:\n",
      "        if id in ref_dict.keys():\n",
      "            continue\n",
      "        else:\n",
      "            ref_dict[id] = parse_doc(fetch_doc(id), id)\n",
      "print('done; compiled {0} entries'.format(len(ref_dict.keys())))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=w6XQzFf6ycG2o8Lo&start=31&70"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=etk2t-1hGR-CIHaQ&start=131&190"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=fBuTEpjT-6EPeJxM&start=231&168"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=57e0DmSA_xW02-nT&start=331&181"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=AEO0Km8LJBorHeB4&start=431&196"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=2Ldg9dEpNVvkX8EE&start=531&170"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=75-2DHdXSISL_2rd&start=631&193"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=7S6UL65mY96BD6gf&start=731&164"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=hoLSlHT9CobT2gxo&start=831&178"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=MsUV_BcrWwGpttpe&start=931&189"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=35MxMId17EA_8I8Q&start=1031&182"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=VhHWJ7N3DC2AflPw&start=1131&199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=LU2n-jnLRG4Arw-5&start=1231&222"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=Iv3VlFjbP0MbL_jH&start=1331&189"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=0vg9QKuqrfA1U0hV&start=1431&235"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=hXDDwllewZ9iZUIe&start=1531&187"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=L_A5Pnm1DmcQX3wr&start=1631&201"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=E7z0KqRxj4Ojce6B&start=1731&191"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=FC2wiIHZURUDSzdp&start=1831&188"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=JMr3UyhyS1pszujU&start=1931&221"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=KWpuXsUcCg6p7PxO&start=2031&213"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=nl53F2aDjfbRvaxW&start=2131&230"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=G14piJF3vo8xvoQG&start=2231&184"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=xcC6McjviXD23M60&start=2331&194"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=Bql0JkCcOq6aA1_h&start=2431&240"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=VqWDY6ge-MQYPLcj&start=2531&223"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=NOhwqX53RPue_11n&start=2631&210"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=0fDCatL2hd9CVXpw&start=2731&221"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=MEW15LEaXVJDxT_f&start=2831&253"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=fTS0DxWZNA-Xnnoz&start=2931&212"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=-VFmMSWgSg2r6Q-6&start=3031&225"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=foDe1wfSslft9qJM&start=3131&210"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=FRMieBfoqwE76VYL&start=3231&248"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=NsYMk6WDI8dhJ-je&start=3331&232"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=sX6ksvCIwc00tXOf&start=3431&251"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=vCgRE6FOf8UTpXVf&start=3531&240"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=qr01_wyg8959b4G9&start=3631&248"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=-_wkvgr-63QeX5UX&start=3731&263"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=OKhPnVG8eT_8ME_X&start=3831&266"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=9en2QtJsnKEzXqGE&start=3931&259"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=u8Rq3mfnAl_ArqGM&start=4031&269"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=X0IHNinbAZuE8Niw&start=4131&271"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=1fMb5tY4BOTvYjuk&start=4231&249"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=4uzNKudhlDI84DKW&start=4331&257"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=CQ4i1IcqEiXdpKiy&start=4431&277"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=QIwCfElNuu0cehfu&start=4531&298"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=REi92iB-AFk7m1rb&start=4631&290"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=NKiQHqsXFWXyii6o&start=4731&293"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=Ajx3tFZDXlgO1yt2&start=4831&308"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=J51uu3scXegufc-p&start=4931&300"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=TQjPCumzJlG8SgNY&start=5031&290"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=lca3Gqe9OMaQ4C6G&start=5131&302"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=4vOmxDdsX1D3JfAE&start=5231&306"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing...\thttp://lingbuzz.auf.net/lingbuzz?_s=HopdRLk0c_IZfDch&_k=U3HtMOlCFyP7TzbY&start=5331&309"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done; compiled 2723 entries"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Supplementary processing:\n",
      "\n",
      "* Change the number of downloads into an integer.\n",
      "* Change the keywords entry into a list of keywords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k in ref_dict.keys():\n",
      "    ref_dict[k]['cnt'] = int(re.search(r'\\d+', ref_dict[k]['cnt']).group())\n",
      "    keywords = list()\n",
      "    for kw in ref_dict[k]['kwd'].split(','):\n",
      "        keywords.append(kw.strip())\n",
      "    ref_dict[k]['kwd'] = keywords"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3 - Save Corpus\n",
      "\n",
      "Save the corpus a JSON file.\n",
      "\n",
      "_(NOTA: to ensure compatibility with python 3.4, replace 'wb' with 'w')_"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('lingbuzzCorpus.json', 'wb') as output:\n",
      "    json.dump(ref_dict, output, indent = 4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    }
   ],
   "metadata": {}
  }
 ]
}